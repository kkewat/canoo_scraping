# -*- coding: utf-8 -*-
"""scrapping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HpGGTOi9aVVXd62ylA1OZwW_YPHAU7Cq
"""

import requests
from bs4 import BeautifulSoup
import pandas as pd

target_url = f"https://finance.yahoo.com/quote/GOEV/?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAEzfFvGMcz4wylBe-_wG9ddbTi1qEd3dRKt7q3Q-NlOGl55thuhzXJiL9sUx_5vh52ISaLzeVZA774HcR8b2ofSLBOjRhDioBfhjzWWizuKEwTHFndtr4xHyZREWXSasFrb3eCy3cEQXu9GTjsOKHc0xGP6KcYvlloi7dBMenzqv"

response = requests.get(target_url)

content = response.content
parsed_content = BeautifulSoup(content,'html.parser')

# Extracting the relevant data
obj = {}
try:
  obj["name"] = parsed_content.find("h1").text.strip()
except:
  obj["name"] = None
try:
  obj["stock_currentprice"] = parsed_content.find("span", {"class": "e3b14781 e59c8479"}).text.strip()
except:
  obj["stock_currentprice"] = None

tables = parsed_content.find("table").find_all("tbody")
# Initialize an empty list to store the extracted text
extracted_text = []

# Iterate over each row in the table
for row in parsed_content.find_all('tr'):
    # Extract the text from each cell (td or th) in the row
    row_text = [cell.get_text(strip=True) for cell in row.find_all(['td', 'th'])]
    extracted_text.append(row_text)

# Display the extracted text
for row in extracted_text:
    print(row)

print(obj)

# Create a DataFrame from the extracted text
df = pd.DataFrame(extracted_text)

# Create a DataFrame for the 'obj' data
obj_df = pd.DataFrame([obj])

# Concatenate the DataFrames vertically (add 'obj_df' at the beginning)
combined_df = pd.concat([obj_df, df], ignore_index=True)

# Save the combined DataFrame to a CSV file
combined_df.to_csv('combined_data.csv', index=False)
